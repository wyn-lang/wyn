// Stage 1: Minimal Lexer - Output JSON tokens
var g_src = ""
var g_pos = 0

fn pk() -> int {
    if g_pos >= g_src.len() { return 0 }
    return g_src.char_at(g_pos)
}

fn adv() {
    g_pos = g_pos + 1
}

fn skip() {
    while pk() == 32 or pk() == 9 or pk() == 10 { adv() }
}

fn is_alpha(c: int) -> int {
    return (c >= 65 and c <= 90) or (c >= 97 and c <= 122) or c == 95
}

fn is_digit(c: int) -> int {
    return c >= 48 and c <= 57
}

fn lex_word() -> string {
    var s = g_pos
    while is_alpha(pk()) or is_digit(pk()) { adv() }
    return g_src.substring(s, g_pos)
}

fn lex_num() -> string {
    var s = g_pos
    while is_digit(pk()) { adv() }
    return g_src.substring(s, g_pos)
}

fn is_kw(w: string) -> int {
    if w == "fn" { return 1 }
    if w == "var" { return 1 }
    if w == "return" { return 1 }
    if w == "if" { return 1 }
    if w == "while" { return 1 }
    return 0
}

fn tok_name(w: string) -> string {
    if w == "fn" { return "FN" }
    if w == "var" { return "VAR" }
    if w == "return" { return "RET" }
    if w == "if" { return "IF" }
    if w == "while" { return "WHILE" }
    return "ID"
}

fn next_tok() -> string {
    skip()
    var c = pk()
    if c == 0 { return "EOF:" }
    
    if is_alpha(c) {
        var w = lex_word()
        return tok_name(w) + ":" + w
    }
    
    if is_digit(c) {
        var n = lex_num()
        return "NUM:" + n
    }
    
    adv()
    if c == 40 { return "LP:(" }
    if c == 41 { return "RP:)" }
    if c == 123 { return "LB:{" }
    if c == 125 { return "RB:}" }
    if c == 58 { return "COL::" }
    if c == 44 { return "COM:," }
    if c == 43 { return "PLUS:+" }
    if c == 45 {
        if pk() == 62 {
            adv()
            return "ARR:->"
        }
        return "MIN:-"
    }
    if c == 42 { return "MUL:*" }
    if c == 61 { return "EQ:=" }
    
    return "UNK:?"
}

fn main() -> int {
    g_src = File::read("input.wyn")
    g_pos = 0
    
    var out = ""
    while g_pos < g_src.len() {
        var t = next_tok()
        out = out + t + "\n"
    }
    
    File::write("tokens.txt", out)
    print("Lexer complete\n")
    return 0
}
