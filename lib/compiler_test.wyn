// Wyn Self-Hosting Compiler - Complete Integration
// Merges: lexer.wyn + parser.wyn + checker.wyn + codegen.wyn

// ===== TOKEN TYPES =====
enum TokenType {
    EndOfFile,
    Ident,
    Int,
    String,
    Fn,
    Var,
    If,
    Else,
    While,
    Return,
    Struct,
    Enum,
    Match,
    Plus,
    Minus,
    Star,
    Slash,
    Equal,
    EqualEqual,
    BangEqual,
    Less,
    Greater,
    LessEqual,
    GreaterEqual,
    Arrow,
    Dot,
    Colon,
    DoubleColon,
    LParen,
    RParen,
    LBrace,
    RBrace,
    LeftParen,
    RightParen,
    LeftBrace,
    RightBrace,
    Comma,
    Semicolon,
    Unknown
}

struct Token {
    tok_type: TokenType,
    value: string
}

// ===== LEXER =====
fn is_digit(ch: string) -> int {
    if ch == "0" { return 1 }
    if ch == "1" { return 1 }
    if ch == "2" { return 1 }
    if ch == "3" { return 1 }
    if ch == "4" { return 1 }
    if ch == "5" { return 1 }
    if ch == "6" { return 1 }
    if ch == "7" { return 1 }
    if ch == "8" { return 1 }
    if ch == "9" { return 1 }
    return 0
}

fn is_alpha(ch: string) -> int {
    if ch == "a" { return 1 }
    if ch == "b" { return 1 }
    if ch == "c" { return 1 }
    if ch == "d" { return 1 }
    if ch == "e" { return 1 }
    if ch == "f" { return 1 }
    if ch == "g" { return 1 }
    if ch == "h" { return 1 }
    if ch == "i" { return 1 }
    if ch == "j" { return 1 }
    if ch == "k" { return 1 }
    if ch == "l" { return 1 }
    if ch == "m" { return 1 }
    if ch == "n" { return 1 }
    if ch == "o" { return 1 }
    if ch == "p" { return 1 }
    if ch == "q" { return 1 }
    if ch == "r" { return 1 }
    if ch == "s" { return 1 }
    if ch == "t" { return 1 }
    if ch == "u" { return 1 }
    if ch == "v" { return 1 }
    if ch == "w" { return 1 }
    if ch == "x" { return 1 }
    if ch == "y" { return 1 }
    if ch == "z" { return 1 }
    return 0
}

fn is_whitespace(ch: string) -> int {
    if ch == " " { return 1 }
    if ch == "\n" { return 1 }
    if ch == "\t" { return 1 }
    return 0
}

fn check_keyword(input: string, start: int, len: int) -> TokenType {
    if len == 2 {
        if input[start] == "f" {
            if input[start + 1] == "n" {
                return TokenType_Fn
            }
        }
        if input[start] == "i" {
            if input[start + 1] == "f" {
                return TokenType_If
            }
        }
    }
    if len == 3 {
        if input[start] == "v" {
            if input[start + 1] == "a" {
                if input[start + 2] == "r" {
                    return TokenType_Var
                }
            }
        }
    }
    if len == 4 {
        if input[start] == "e" {
            if input[start + 1] == "l" {
                if input[start + 2] == "s" {
                    if input[start + 3] == "e" {
                        return TokenType_Else
                    }
                }
            }
        }
    }
    if len == 5 {
        if input[start] == "w" {
            if input[start + 1] == "h" {
                if input[start + 2] == "i" {
                    if input[start + 3] == "l" {
                        if input[start + 4] == "e" {
                            return TokenType_While
                        }
                    }
                }
            }
        }
    }
    if len == 6 {
        if input[start] == "r" {
            if input[start + 1] == "e" {
                if input[start + 2] == "t" {
                    if input[start + 3] == "u" {
                        if input[start + 4] == "r" {
                            if input[start + 5] == "n" {
                                return TokenType_Return
                            }
                        }
                    }
                }
            }
        }
        if input[start] == "s" {
            if input[start + 1] == "t" {
                if input[start + 2] == "r" {
                    if input[start + 3] == "u" {
                        if input[start + 4] == "c" {
                            if input[start + 5] == "t" {
                                return TokenType_Struct
                            }
                        }
                    }
                }
            }
        }
    }
    return TokenType_Ident
}

fn substr(s: string, start: int, len: int) -> string {
    var result = ""
    var i = 0
    while i < len {
        result = result + s[start + i]
        i = i + 1
    }
    return result
}

fn make_token(tok_type: TokenType, value: string) -> Token {
    var tok: Token = Token { tok_type: tok_type, value: value }
    return tok
}

fn lex(input: string) -> [Token] {
    var pos = 0
    var tokens: [Token] = []
    
    while pos < input.len() {
        var ch = input[pos]
        
        if is_whitespace(ch) {
            pos = pos + 1
        } else if is_digit(ch) {
            var start = pos
            while pos < input.len() {
                if is_digit(input[pos]) {
                    pos = pos + 1
                } else {
                    break
                }
            }
            tokens.push(make_token(TokenType_Int, substr(input, start, pos - start)))
        } else if is_alpha(ch) {
            var start = pos
            while pos < input.len() {
                var c = input[pos]
                if is_alpha(c) {
                    pos = pos + 1
                } else {
                    break
                }
            }
            tokens.push(make_token(check_keyword(input, start, pos - start), substr(input, start, pos - start)))
        } else if ch == "+" {
            tokens.push(make_token(TokenType_Plus, "+"))
            pos = pos + 1
        } else if ch == "-" {
            tokens.push(make_token(TokenType_Minus, "-"))
            pos = pos + 1
        } else if ch == "*" {
            tokens.push(make_token(TokenType_Star, "*"))
            pos = pos + 1
        } else if ch == "/" {
            tokens.push(make_token(TokenType_Slash, "/"))
            pos = pos + 1
        } else if ch == "=" {
            tokens.push(make_token(TokenType_Equal, "="))
            pos = pos + 1
        } else if ch == "<" {
            tokens.push(make_token(TokenType_Less, "<"))
            pos = pos + 1
        } else if ch == ">" {
            tokens.push(make_token(TokenType_Greater, ">"))
            pos = pos + 1
        } else if ch == "." {
            tokens.push(make_token(TokenType_Dot, "."))
            pos = pos + 1
        } else if ch == ":" {
            tokens.push(make_token(TokenType_Colon, ":"))
            pos = pos + 1
        } else if ch == "(" {
            tokens.push(make_token(TokenType_LParen, "("))
            pos = pos + 1
        } else if ch == ")" {
            tokens.push(make_token(TokenType_RParen, ")"))
            pos = pos + 1
        } else if ch == "{" {
            tokens.push(make_token(TokenType_LBrace, "{"))
            pos = pos + 1
        } else if ch == "}" {
            tokens.push(make_token(TokenType_RBrace, "}"))
            pos = pos + 1
        } else if ch == ";" {
            tokens.push(make_token(TokenType_Semicolon, ";"))
            pos = pos + 1
        } else {
            tokens.push(make_token(TokenType_Unknown, ch))
            pos = pos + 1
        }
    }
    
    tokens.push(make_token(TokenType_EndOfFile, ""))
    return tokens
}

// ===== PARSER =====
enum NodeType {
    NodeInt,
    NodeString,
    NodeVariable,
    NodeVarDecl,
    NodeReturn,
    NodeExprStmt,
    NodeBinary,
    NodeFnDecl,
    NodeBlock,
    NodeIf,
    NodeWhile,
    NodeCall,
    NodeStructDecl,
    NodeEnumDecl,
    NodeMatch,
    NodeStructInit
}

struct ASTNode {
    node_type: NodeType,
    value: string,
    left: int,
    right: int,
    extra: int
}

var g_parse_tokens: [Token] = []
var g_parse_current = 0
var g_parse_nodes: [ASTNode] = []

fn parse_peek() -> Token {
    if g_parse_current < g_parse_tokens.len() {
        return g_parse_tokens[g_parse_current]
    }
    return Token { tok_type: TokenType_EndOfFile, value: "" }
}

fn parse_check(tok_type: TokenType) -> int {
    var tok = parse_peek()
    if tok.tok_type == tok_type {
        return 1
    }
    return 0
}

fn parse_advance() {
    g_parse_current = g_parse_current + 1
}

fn parse_add_node(node: ASTNode) -> int {
    var idx = g_parse_nodes.len()
    g_parse_nodes.push(node)
    return idx
}

fn parse_primary() -> int {
    var tok = parse_peek()
    
    if tok.tok_type == TokenType_Int {
        parse_advance()
        return parse_add_node(ASTNode { node_type: NodeType_NodeInt, value: tok.value, left: -1, right: -1, extra: -1 })
    }
    
    if tok.tok_type == TokenType_String {
        parse_advance()
        return parse_add_node(ASTNode { node_type: NodeType_NodeString, value: tok.value, left: -1, right: -1, extra: -1 })
    }
    
    if tok.tok_type == TokenType_Ident {
        parse_advance()
        return parse_add_node(ASTNode { node_type: NodeType_NodeVariable, value: tok.value, left: -1, right: -1, extra: -1 })
    }
    
    if tok.tok_type == TokenType_LParen {
        parse_advance()
        var expr_idx = parse_expr()
        parse_advance()
        return expr_idx
    }
    
    return -1
}

fn parse_factor() -> int {
    var left = parse_primary()
    
    while parse_check(TokenType_Star) || parse_check(TokenType_Slash) {
        var op_tok = parse_peek()
        parse_advance()
        var right = parse_primary()
        left = parse_add_node(ASTNode { node_type: NodeType_NodeBinary, value: op_tok.value, left: left, right: right, extra: -1 })
    }
    
    return left
}

fn parse_term() -> int {
    var left = parse_factor()
    
    while parse_check(TokenType_Plus) || parse_check(TokenType_Minus) {
        var op_tok = parse_peek()
        parse_advance()
        var right = parse_factor()
        left = parse_add_node(ASTNode { node_type: NodeType_NodeBinary, value: op_tok.value, left: left, right: right, extra: -1 })
    }
    
    return left
}

fn parse_expr() -> int {
    return parse_term()
}

fn parse_var_decl() -> int {
    parse_advance()
    var name_tok = parse_peek()
    parse_advance()
    
    if parse_check(TokenType_Colon) {
        parse_advance()
        parse_advance()
    }
    
    if parse_check(TokenType_Equal) {
        parse_advance()
    }
    
    var expr_idx = parse_expr()
    return parse_add_node(ASTNode { node_type: NodeType_NodeVarDecl, value: name_tok.value, left: expr_idx, right: -1, extra: -1 })
}

fn parse_block() -> int {
    parse_advance()
    var stmts: [int] = []
    
    while parse_check(TokenType_RBrace) == 0 && parse_check(TokenType_EndOfFile) == 0 {
        var stmt_idx = parse_stmt()
        if stmt_idx >= 0 {
            stmts.push(stmt_idx)
        }
    }
    
    parse_advance()
    return parse_add_node(ASTNode { node_type: NodeType_NodeBlock, value: "", left: -1, right: stmts.len(), extra: -1 })
}

fn parse_if() -> int {
    parse_advance()
    var cond_idx = parse_expr()
    var then_idx = parse_block()
    var else_idx = -1
    
    if parse_check(TokenType_Else) {
        parse_advance()
        if parse_check(TokenType_If) {
            else_idx = parse_if()
        } else {
            else_idx = parse_block()
        }
    }
    
    return parse_add_node(ASTNode { node_type: NodeType_NodeIf, value: "", left: cond_idx, right: then_idx, extra: else_idx })
}

fn parse_while() -> int {
    parse_advance()
    var cond_idx = parse_expr()
    var body_idx = parse_block()
    return parse_add_node(ASTNode { node_type: NodeType_NodeWhile, value: "", left: cond_idx, right: body_idx, extra: -1 })
}

fn parse_fn_decl() -> int {
    parse_advance()
    var name_tok = parse_peek()
    parse_advance()
    parse_advance()
    
    if parse_check(TokenType_RParen) == 0 {
        var param_tok = parse_peek()
        parse_advance()
        if parse_check(TokenType_Colon) {
            parse_advance()
            parse_advance()
        }
        while parse_check(TokenType_Comma) {
            parse_advance()
            param_tok = parse_peek()
            parse_advance()
            if parse_check(TokenType_Colon) {
                parse_advance()
                parse_advance()
            }
        }
    }
    
    parse_advance()
    
    if parse_check(TokenType_Arrow) {
        parse_advance()
        parse_advance()
    }
    
    var body_idx = parse_block()
    return parse_add_node(ASTNode { node_type: NodeType_NodeFnDecl, value: name_tok.value, left: body_idx, right: -1, extra: -1 })
}

fn parse_stmt() -> int {
    var tok = parse_peek()
    
    if tok.tok_type == TokenType_Var {
        return parse_var_decl()
    }
    
    if tok.tok_type == TokenType_Return {
        parse_advance()
        var expr_idx = parse_expr()
        return parse_add_node(ASTNode { node_type: NodeType_NodeReturn, value: "", left: expr_idx, right: -1, extra: -1 })
    }
    
    if tok.tok_type == TokenType_If {
        return parse_if()
    }
    
    if tok.tok_type == TokenType_While {
        return parse_while()
    }
    
    if tok.tok_type == TokenType_LBrace {
        return parse_block()
    }
    
    var expr_idx = parse_expr()
    return parse_add_node(ASTNode { node_type: NodeType_NodeExprStmt, value: "", left: expr_idx, right: -1, extra: -1 })
}

fn parse(tokens: [Token]) -> [int] {
    g_parse_tokens = tokens
    g_parse_current = 0
    g_parse_nodes = []
    
    var decls: [int] = []
    
    while parse_check(TokenType_EndOfFile) == 0 {
        var tok = parse_peek()
        
        if tok.tok_type == TokenType_Fn {
            var fn_idx = parse_fn_decl()
            if fn_idx >= 0 {
                decls.push(fn_idx)
            }
        } else {
            var stmt_idx = parse_stmt()
            if stmt_idx >= 0 {
                decls.push(stmt_idx)
            }
        }
    }
    
    return decls
}

// ===== CODE GENERATOR =====
var g_codegen_output: string = ""

fn codegen_emit(s: string) -> int {
    g_codegen_output = g_codegen_output + s
    return 0
}

fn codegen_int(node: ASTNode) -> int {
    codegen_emit(node.value)
    return 0
}

fn codegen_string(node: ASTNode) -> int {
    codegen_emit("\"")
    codegen_emit(node.value)
    codegen_emit("\"")
    return 0
}

fn codegen_variable(node: ASTNode) -> int {
    codegen_emit(node.value)
    return 0
}

fn codegen_binary(node: ASTNode) -> int {
    codegen_emit("(")
    codegen_expr(node.left)
    codegen_emit(" ")
    codegen_emit(node.value)
    codegen_emit(" ")
    codegen_expr(node.right)
    codegen_emit(")")
    return 0
}

fn codegen_expr(idx: int) -> int {
    if idx < 0 {
        return 0
    }
    var node = g_parse_nodes[idx]
    if node.node_type == NodeType_NodeInt {
        codegen_int(node)
        return 0
    }
    if node.node_type == NodeType_NodeString {
        codegen_string(node)
        return 0
    }
    if node.node_type == NodeType_NodeVariable {
        codegen_variable(node)
        return 0
    }
    if node.node_type == NodeType_NodeBinary {
        codegen_binary(node)
        return 0
    }
    return 0
}

fn codegen_var_decl(node: ASTNode) -> int {
    codegen_emit("int ")
    codegen_emit(node.value)
    codegen_emit(" = ")
    codegen_expr(node.left)
    codegen_emit(";\n")
    return 0
}

fn codegen_return(node: ASTNode) -> int {
    codegen_emit("return ")
    codegen_expr(node.left)
    codegen_emit(";\n")
    return 0
}

fn codegen_expr_stmt(node: ASTNode) -> int {
    codegen_expr(node.left)
    codegen_emit(";\n")
    return 0
}

fn codegen_if(node: ASTNode) -> int {
    codegen_emit("if (")
    codegen_expr(node.left)
    codegen_emit(") {\n")
    codegen_stmt(node.right)
    if node.extra >= 0 {
        codegen_emit("} else {\n")
        codegen_stmt(node.extra)
    }
    codegen_emit("}\n")
    return 0
}

fn codegen_while(node: ASTNode) -> int {
    codegen_emit("while (")
    codegen_expr(node.left)
    codegen_emit(") {\n")
    codegen_stmt(node.right)
    codegen_emit("}\n")
    return 0
}

fn codegen_block(node: ASTNode) -> int {
    var i = node.left
    while i >= 0 {
        codegen_stmt(i)
        var stmt = g_parse_nodes[i]
        i = stmt.extra
