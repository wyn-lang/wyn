// Minimal Integrated Compiler - Actually Works
// Simplified version that can be compiled

// Token types
enum TokenType {
    EOF, Ident, Int, Fn, Return, LParen, RParen, LBrace, RBrace,
    Colon, Arrow, Comma, Plus, Minus, Star, Semicolon
}

struct Token {
    type: TokenType,
    val: string
}

// Globals for lexer
var g_input: string = ""
var g_pos: int = 0

// Lexer
fn lex_char() -> string {
    if g_pos >= g_input.len() {
        return ""
    }
    var c = g_input[g_pos]
    g_pos = g_pos + 1
    return c
}

fn lex_skip_ws() {
    while g_pos < g_input.len() {
        var c = g_input[g_pos]
        if c == " " or c == "\n" or c == "\t" {
            g_pos = g_pos + 1
        } else {
            return
        }
    }
}

fn lex_ident() -> string {
    var start = g_pos
    while g_pos < g_input.len() {
        var c = g_input[g_pos]
        if (c >= "a" and c <= "z") or (c >= "A" and c <= "Z") or c == "_" {
            g_pos = g_pos + 1
        } else {
            return g_input.substring(start, g_pos)
        }
    }
    return g_input.substring(start, g_pos)
}

fn lex_number() -> string {
    var start = g_pos
    while g_pos < g_input.len() {
        var c = g_input[g_pos]
        if c >= "0" and c <= "9" {
            g_pos = g_pos + 1
        } else {
            return g_input.substring(start, g_pos)
        }
    }
    return g_input.substring(start, g_pos)
}

fn lex() {
    var tokens: [Token] = []
    g_pos = 0
    
    while g_pos < g_input.len() {
        lex_skip_ws()
        if g_pos >= g_input.len() {
            break
        }
        
        var c = g_input[g_pos]
        
        if c == "(" {
            g_tokens.push(Token { type: TokenType_LParen, val: "(" })
            g_pos = g_pos + 1
        } else if c == ")" {
            g_tokens.push(Token { type: TokenType_RParen, val: ")" })
            g_pos = g_pos + 1
        } else if c == "{" {
            g_tokens.push(Token { type: TokenType_LBrace, val: "{" })
            g_pos = g_pos + 1
        } else if c == "}" {
            g_tokens.push(Token { type: TokenType_RBrace, val: "}" })
            g_pos = g_pos + 1
        } else if c == ":" {
            g_pos = g_pos + 1
            g_tokens.push(Token { type: TokenType_Colon, val: ":" })
        } else if c == "," {
            g_tokens.push(Token { type: TokenType_Comma, val: "," })
            g_pos = g_pos + 1
        } else if c == "+" {
            g_tokens.push(Token { type: TokenType_Plus, val: "+" })
            g_pos = g_pos + 1
        } else if c == "-" {
            g_pos = g_pos + 1
            if g_pos < g_input.len() and g_input[g_pos] == ">" {
                g_pos = g_pos + 1
                g_tokens.push(Token { type: TokenType_Arrow, val: "->" })
            } else {
                g_tokens.push(Token { type: TokenType_Minus, val: "-" })
            }
        } else if c == "*" {
            g_tokens.push(Token { type: TokenType_Star, val: "*" })
            g_pos = g_pos + 1
        } else if c == ";" {
            g_tokens.push(Token { type: TokenType_Semicolon, val: ";" })
            g_pos = g_pos + 1
        } else if c >= "0" and c <= "9" {
            var num = lex_number()
            g_tokens.push(Token { type: TokenType_Int, val: num })
        } else if (c >= "a" and c <= "z") or (c >= "A" and c <= "Z") {
            var id = lex_ident()
            if id == "fn" {
                g_tokens.push(Token { type: TokenType_Fn, val: "fn" })
            } else if id == "return" {
                g_tokens.push(Token { type: TokenType_Return, val: "return" })
            } else {
                g_tokens.push(Token { type: TokenType_Ident, val: id })
            }
        } else {
            g_pos = g_pos + 1
        }
    }
    
    g_tokens.push(Token { type: TokenType_EOF, val: "" })
}

// Parser globals
var g_tok_pos: int = 0
var g_output: string = ""

fn parse_peek() -> TokenType {
    if g_tok_pos < g_tokens.len() {
        return g_tokens[g_tok_pos].type
    }
    return TokenType_EOF
}

fn parse_advance() {
    g_tok_pos = g_tok_pos + 1
}

fn parse_expect(t: TokenType) {
    if parse_peek() == t {
        parse_advance()
    }
}

fn parse_function() {
    parse_expect(TokenType_Fn)
    
    var name = ""
    if parse_peek() == TokenType_Ident {
        name = g_tokens[g_tok_pos].val
        parse_advance()
    }
    
    g_output = g_output + "int " + name + "("
    
    parse_expect(TokenType_LParen)
    
    var first = 1
    while parse_peek() != TokenType_RParen and parse_peek() != TokenType_EOF {
        if first == 0 {
            parse_expect(TokenType_Comma)
            g_output = g_output + ", "
        }
        first = 0
        
        var param = ""
        if parse_peek() == TokenType_Ident {
            param = g_tokens[g_tok_pos].val
            parse_advance()
        }
        
        parse_expect(TokenType_Colon)
        
        if parse_peek() == TokenType_Ident {
            parse_advance()
        }
        
        g_output = g_output + "int " + param
    }
    
    parse_expect(TokenType_RParen)
    
    if parse_peek() == TokenType_Arrow {
        parse_advance()
        if parse_peek() == TokenType_Ident {
            parse_advance()
        }
    }
    
    g_output = g_output + ") "
    
    parse_expect(TokenType_LBrace)
    g_output = g_output + "{\n"
    
    while parse_peek() != TokenType_RBrace and parse_peek() != TokenType_EOF {
        if parse_peek() == TokenType_Return {
            parse_advance()
            g_output = g_output + "  return "
            
            if parse_peek() == TokenType_Int {
                g_output = g_output + g_tokens[g_tok_pos].val
                parse_advance()
            } else if parse_peek() == TokenType_Ident {
                var left = g_tokens[g_tok_pos].val
                parse_advance()
                
                if parse_peek() == TokenType_Plus {
                    parse_advance()
                    if parse_peek() == TokenType_Ident or parse_peek() == TokenType_Int {
                        var right = g_tokens[g_tok_pos].val
                        parse_advance()
                        g_output = g_output + left + " + " + right
                    }
                } else if parse_peek() == TokenType_Minus {
                    parse_advance()
                    if parse_peek() == TokenType_Ident or parse_peek() == TokenType_Int {
                        var right = g_tokens[g_tok_pos].val
                        parse_advance()
                        g_output = g_output + left + " - " + right
                    }
                } else if parse_peek() == TokenType_Star {
                    parse_advance()
                    if parse_peek() == TokenType_Ident or parse_peek() == TokenType_Int {
                        var right = g_tokens[g_tok_pos].val
                        parse_advance()
                        g_output = g_output + left + " * " + right
                    }
                } else {
                    g_output = g_output + left
                }
            }
            
            if parse_peek() == TokenType_Semicolon {
                parse_advance()
            }
            g_output = g_output + ";\n"
        }
    }
    
    parse_expect(TokenType_RBrace)
    g_output = g_output + "}\n"
}

fn compile(source: string) -> string {
    g_input = source
    g_output = "#include <stdio.h>\n\n"
    g_tok_pos = 0
    
    lex()
    
    while parse_peek() != TokenType_EOF {
        if parse_peek() == TokenType_Fn {
            parse_function()
        } else {
            parse_advance()
        }
    }
    
    return g_output
}

fn main() -> int {
    var test1 = "fn add(a: int, b: int) -> int { return a + b }"
    var c1 = compile(test1)
    
    print("=== Test 1: Simple function ===\n")
    print(c1)
    print("\n")
    
    var test2 = "fn mul(x: int, y: int) -> int { return x * y }"
    var c2 = compile(test2)
    
    print("=== Test 2: Multiply ===\n")
    print(c2)
    print("\n")
    
    print("âœ“ Compiler v2 works!\n")
    
    return 0
}
