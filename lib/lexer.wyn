// Lexer for Wyn written in Wyn
// Proof of concept for self-hosting

enum TokenType {
    EndOfFile,
    Ident,
    Int,
    String,
    
    // Keywords
    Fn,
    Var,
    If,
    Else,
    While,
    Return,
    
    // Operators
    Plus,
    Minus,
    Star,
    Slash,
    Equal,
    EqualEqual,
    Less,
    Greater,
    Arrow,
    Dot,
    Colon,
    
    // Delimiters
    LParen,
    RParen,
    LBrace,
    RBrace,
    Comma,
    Semicolon,
    
    Unknown
}

fn is_digit(ch: string) -> int {
    if ch == "0" { return 1 }
    if ch == "1" { return 1 }
    if ch == "2" { return 1 }
    if ch == "3" { return 1 }
    if ch == "4" { return 1 }
    if ch == "5" { return 1 }
    if ch == "6" { return 1 }
    if ch == "7" { return 1 }
    if ch == "8" { return 1 }
    if ch == "9" { return 1 }
    return 0
}

fn is_alpha(ch: string) -> int {
    // Simplified: just check a few letters
    if ch == "a" { return 1 }
    if ch == "b" { return 1 }
    if ch == "f" { return 1 }
    if ch == "n" { return 1 }
    if ch == "r" { return 1 }
    if ch == "v" { return 1 }
    if ch == "x" { return 1 }
    if ch == "y" { return 1 }
    // TODO: Add full alphabet
    return 0
}

fn is_whitespace(ch: string) -> int {
    if ch == " " { return 1 }
    if ch == "\n" { return 1 }
    if ch == "\t" { return 1 }
    return 0
}

fn check_keyword(input: string, start: int, len: int) {
    // Returns TokenType for keyword, or TokenType_Ident if not a keyword
    
    // Check "fn" (length 2)
    if len == 2 {
        if input[start] == "f" {
            if input[start + 1] == "n" {
                return TokenType_Fn
            }
        }
    }
    
    // Check "if" (length 2)
    if len == 2 {
        if input[start] == "i" {
            if input[start + 1] == "f" {
                return TokenType_If
            }
        }
    }
    
    // Check "var" (length 3)
    if len == 3 {
        if input[start] == "v" {
            if input[start + 1] == "a" {
                if input[start + 2] == "r" {
                    return TokenType_Var
                }
            }
        }
    }
    
    // Not a keyword
    return TokenType_Ident
}

fn lex(input: string) -> [int] {
    var pos = 0
    var tokens = []
    
    while pos < input.len() {
        var ch = input[pos]
        
        if is_whitespace(ch) {
            pos = pos + 1
        } else if is_digit(ch) {
            tokens.push(TokenType_Int)
            while pos < input.len() {
                if is_digit(input[pos]) {
                    pos = pos + 1
                } else {
                    break
                }
            }
        } else if is_alpha(ch) {
            var ident_start = pos
            while pos < input.len() {
                var c = input[pos]
                if is_alpha(c) {
                    pos = pos + 1
                } else {
                    break
                }
            }
            var ident_len = pos - ident_start
            var token_type = check_keyword(input, ident_start, ident_len)
            tokens.push(token_type)
        } else if ch == "+" {
            tokens.push(TokenType_Plus)
            pos = pos + 1
        } else if ch == "-" {
            tokens.push(TokenType_Minus)
            pos = pos + 1
        } else if ch == "*" {
            tokens.push(TokenType_Star)
            pos = pos + 1
        } else if ch == "/" {
            tokens.push(TokenType_Slash)
            pos = pos + 1
        } else if ch == "=" {
            tokens.push(TokenType_Equal)
            pos = pos + 1
        } else if ch == "<" {
            tokens.push(TokenType_Less)
            pos = pos + 1
        } else if ch == ">" {
            tokens.push(TokenType_Greater)
            pos = pos + 1
        } else if ch == "." {
            tokens.push(TokenType_Dot)
            pos = pos + 1
        } else if ch == ":" {
            tokens.push(TokenType_Colon)
            pos = pos + 1
        } else if ch == "(" {
            tokens.push(TokenType_LParen)
            pos = pos + 1
        } else if ch == ")" {
            tokens.push(TokenType_RParen)
            pos = pos + 1
        } else if ch == "{" {
            tokens.push(TokenType_LBrace)
            pos = pos + 1
        } else if ch == "}" {
            tokens.push(TokenType_RBrace)
            pos = pos + 1
        } else if ch == ";" {
            tokens.push(TokenType_Semicolon)
            pos = pos + 1
        } else {
            tokens.push(TokenType_Unknown)
            pos = pos + 1
        }
    }
    
    tokens.push(TokenType_EndOfFile)
    return tokens
}

fn main() -> int {
    var input = "fn main() { var x = 42 + 10; }"
    var tokens = lex(input)
    
    print("Lexed tokens:")
    print(tokens.len())
    
    if tokens.len() > 10 {
        print("âœ“ Lexer works!")
        return 0
    }
    
    return 1
}
